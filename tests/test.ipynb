{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Annotated, Literal\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.tools.base import InjectedToolCallId\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from langgraph.types import interrupt, Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_travel_recommendations():\n",
    "    \"\"\"Get recommendation for travel destinations\"\"\"\n",
    "    return random.choice([\"aruba\", \"turks and caicos\"])\n",
    "\n",
    "@tool\n",
    "def get_hotel_recommendations(location: Literal[\"aruba\", \"turks and caicos\"]):\n",
    "    \"\"\"Get hotel recommendations for a given destination.\"\"\"\n",
    "    return {\n",
    "        \"aruba\": [\n",
    "            \"The Ritz-Carlton, Aruba (Palm Beach)\"\n",
    "            \"Bucuti & Tara Beach Resort (Eagle Beach)\"\n",
    "        ],\n",
    "        \"turks and caicos\": [\"Grace Bay Club\", \"COMO Parrot Cay\"],\n",
    "    }[location]\n",
    "\n",
    "def make_handoff_tool(*, agent_name: str):\n",
    "    \"\"\"Create a tool that can return handoff via a Command\"\"\"\n",
    "    tool_name = f\"transfer_to_{agent_name}\"\n",
    "\n",
    "    @tool(tool_name)\n",
    "    def handoff_to_agent(\n",
    "        state: Annotated[dict, InjectedState],\n",
    "        tool_call_id: Annotated[str, InjectedToolCallId],\n",
    "    ):\n",
    "        \"\"\"Ask another agent for help.\"\"\"\n",
    "        tool_message = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": f\"Successfully transferred to {agent_name}\",\n",
    "            \"name\": tool_name,\n",
    "            \"tool_call_id\": tool_call_id,\n",
    "        }\n",
    "        return Command(\n",
    "            # navigate to another agent node in the PARENT graph\n",
    "            goto=agent_name,\n",
    "            graph=Command.PARENT,\n",
    "            # This is the state update that the agent `agent_name` will see when it is invoked.\n",
    "            # We're passing agent's FULL internal message history AND adding a tool message to make sure\n",
    "            # the resulting chat history is valid.\n",
    "            update={\"messages\": state[\"messages\"] + [tool_message]},\n",
    "        )\n",
    "\n",
    "    return handoff_to_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create our agents using the the prebuilt create_react_agent. We'll also define a dedicated human node with an interrupt -- we will route to this node after the final response from the agents. Note that to do so we're wrapping each agent invocation in a separate node function that returns Command(goto=\"human\", ...).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Command, interrupt\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpoint\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmemory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MemorySaver\n\u001b[0;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclaude-3-5-sonnet-latest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Define travel advisor tools and ReAct agent\u001b[39;00m\n\u001b[1;32m     13\u001b[0m travel_advisor_tools \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     14\u001b[0m     get_travel_recommendations,\n\u001b[1;32m     15\u001b[0m     make_handoff_tool(agent_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhotel_advisor\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     16\u001b[0m ]\n",
      "File \u001b[0;32m~/woo/woo-deep-researcher/env/lib/python3.12/site-packages/langchain_core/load/serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/woo/woo-deep-researcher/env/lib/python3.12/site-packages/langchain_openai/llms/base.py:189\u001b[0m, in \u001b[0;36mBaseOpenAI.validate_environment\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient:\n\u001b[1;32m    188\u001b[0m     sync_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_client}\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mclient_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msync_specific\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcompletions  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39masync_client:\n\u001b[1;32m    191\u001b[0m     async_specific \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp_client\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp_async_client}\n",
      "File \u001b[0;32m~/woo/woo-deep-researcher/env/lib/python3.12/site-packages/openai/_client.py:110\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m    108\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "\n",
    "from langgraph.graph import MessagesState, StateGraph, START\n",
    "from langgraph.prebuilt import create_react_agent, InjectedState\n",
    "from langgraph.types import Command, interrupt\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "model = OpenAI(model=\"gpt-3.5-turbo-1106\")\n",
    "\n",
    "# Define travel advisor tools and ReAct agent\n",
    "travel_advisor_tools = [\n",
    "    get_travel_recommendations,\n",
    "    make_handoff_tool(agent_name=\"hotel_advisor\"),\n",
    "]\n",
    "travel_advisor = create_react_agent(\n",
    "    model,\n",
    "    travel_advisor_tools,\n",
    "    prompt=(\n",
    "        \"You are a general travel expert that can recommend travel destinations (e.g. countries, cities, etc). \"\n",
    "        \"If you need hotel recommendations, ask 'hotel_advisor' for help. \"\n",
    "        \"You MUST include human-readable response before transferring to another agent.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def call_travel_advisor(\n",
    "    state: MessagesState,\n",
    ") -> Command[Literal[\"hotel_advisor\", \"human\"]]:\n",
    "    # You can also add additional logic like changing the input to the agent / output from the agent, etc.\n",
    "    # NOTE: we're invoking the ReAct agent with the full history of messages in the state\n",
    "    response = travel_advisor.invoke(state)\n",
    "    return Command(update=response, goto=\"human\")\n",
    "\n",
    "\n",
    "# Define hotel advisor tools and ReAct agent\n",
    "hotel_advisor_tools = [\n",
    "    get_hotel_recommendations,\n",
    "    make_handoff_tool(agent_name=\"travel_advisor\"),\n",
    "]\n",
    "hotel_advisor = create_react_agent(\n",
    "    model,\n",
    "    hotel_advisor_tools,\n",
    "    prompt=(\n",
    "        \"You are a hotel expert that can provide hotel recommendations for a given destination. \"\n",
    "        \"If you need help picking travel destinations, ask 'travel_advisor' for help.\"\n",
    "        \"You MUST include human-readable response before transferring to another agent.\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "def call_hotel_advisor(\n",
    "    state: MessagesState,\n",
    ") -> Command[Literal[\"travel_advisor\", \"human\"]]:\n",
    "    response = hotel_advisor.invoke(state)\n",
    "    return Command(update=response, goto=\"human\")\n",
    "\n",
    "\n",
    "def human_node(\n",
    "    state: MessagesState, config\n",
    ") -> Command[Literal[\"hotel_advisor\", \"travel_advisor\", \"human\"]]:\n",
    "    \"\"\"A node for collecting user input.\"\"\"\n",
    "\n",
    "    user_input = interrupt(value=\"Ready for user input.\")\n",
    "\n",
    "    # identify the last active agent\n",
    "    # (the last active node before returning to human)\n",
    "    langgraph_triggers = config[\"metadata\"][\"langgraph_triggers\"]\n",
    "    if len(langgraph_triggers) != 1:\n",
    "        raise AssertionError(\"Expected exactly 1 trigger in human node\")\n",
    "\n",
    "    active_agent = langgraph_triggers[0].split(\":\")[1]\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"human\",\n",
    "                    \"content\": user_input,\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        goto=active_agent,\n",
    "    )\n",
    "\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"travel_advisor\", call_travel_advisor)\n",
    "builder.add_node(\"hotel_advisor\", call_hotel_advisor)\n",
    "\n",
    "# This adds a node to collect human input, which will route\n",
    "# back to the active agent.\n",
    "builder.add_node(\"human\", human_node)\n",
    "\n",
    "# We'll always start with a general travel advisor.\n",
    "builder.add_edge(START, \"travel_advisor\")\n",
    "\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "graph = builder.compile(checkpointer=checkpointer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
